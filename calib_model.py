import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

from data_loader import get_dataset
from modules.MobileNetV3 import MobileNetV3
from utils.trainer import Trainer

import json

from modules.QuantMobileNetV3 import QuantMobileNetV3




def load_config_from_json(json_file):
    if json_file is not None:
        with open(json_file, 'r') as f:
            config = json.load(f)
    else:
        raise ValueError("json_file must be provided")
    return config






def model_key_mapping(fp_dict, quant_dict, print_info = True):
    
    # è·å–æŒ‰é¡ºåºæ’åˆ—çš„é”®åˆ—è¡¨
    fp_keys = list(fp_dict.keys())
    quant_keys = list(quant_dict.keys())
    # ç¡®ä¿ä¸¤ä¸ªåˆ—è¡¨é•¿åº¦ç›¸åŒ
    assert len(fp_keys) == len(quant_keys), "Key Numbers Not Match."
    # ç”Ÿæˆæ˜ å°„å­—å…¸
    key_mapping = {fp_key: quant_key for fp_key, quant_key in zip(fp_keys, quant_keys)}

    if print_info:
        # è·å–fp_keysæœ€é•¿å­—ç¬¦ä¸²é•¿åº¦(ä¸ºäº†æ‰“å°ç¾è§‚)
        max_length = max(len(key) for key in fp_keys)

        # æ‰“å°æƒé‡æ˜ å°„å…³ç³»
        print("æƒé‡æ˜ å°„å…³ç³»:")
        print(f"{'Float Model Layers':<{max_length}} -> {'Quantized Model Layers':<{max_length}}")
        for k, v in key_mapping.items():
            print(f"{k:<{max_length}} -> {v:<{max_length}}")

    return key_mapping

def evaluate_model(model, test_loader, device):
    model = model.to(device)
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            # print(type(images), type(labels))
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    return accuracy

from collections import OrderedDict

def compare_models_layerwise(fp_model, quant_model, key_mapping, device='cuda', input_shape=(1, 3, 64, 64)):
    # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
    fp_model.eval()
    quant_model.eval()
    fp_model.to(device)
    quant_model.to(device)

    
    # ç”Ÿæˆå›ºå®šè¾“å…¥æ•°æ®
    torch.manual_seed(42)
    input_data = torch.randn(*input_shape).to(device)
    
    # å­˜å‚¨å„å±‚è¾“å‡º
    fp_outputs = OrderedDict()
    quant_outputs = OrderedDict()

    # è·å–æ¨¡å‹çš„æ‰€æœ‰æ¨¡å—
    fp_modules = dict(fp_model.named_modules())
    quant_modules = dict(quant_model.named_modules())

    # æ„å»ºæ¨¡å—æ˜ å°„å…³ç³»ï¼ˆå‚æ•°å -> æ¨¡å—å®ä¾‹ï¼‰
    module_mapping = {}
    for fp_param, quant_param in key_mapping.items():
        # æå–æ¨¡å—åç§°ï¼ˆå»æ‰å‚æ•°ç±»å‹åç¼€ï¼‰
        fp_module_name = '.'.join(fp_param.split('.')[:-1])
        quant_module_name = '.'.join(quant_param.split('.')[:-1])
        
        # è·å–å¯¹åº”æ¨¡å—å®ä¾‹
        if fp_module_name in fp_modules and quant_module_name in quant_modules:
            module_mapping[fp_modules[fp_module_name]] = quant_modules[quant_module_name]

    # æ³¨å†Œé’©å­çš„å‡½æ•°
    def register_hooks(model, output_dict, model_type):
        hooks = []
        for name, module in model.named_modules():
            def closure(m, name=name):
                def hook(module, input, output):
                    output_dict[f"{model_type}_{name}"] = output.detach()
                return hook
            hooks.append(module.register_forward_hook(closure(module)))
        return hooks

    # ä¸ºä¸¤ä¸ªæ¨¡å‹æ³¨å†Œé’©å­
    fp_hooks = register_hooks(fp_model, fp_outputs, "fp")
    quant_hooks = register_hooks(quant_model, quant_outputs, "quant")

    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        _ = fp_model(input_data)
        _ = quant_model(input_data)

    # ç§»é™¤é’©å­
    for hook in fp_hooks + quant_hooks:
        hook.remove()

    # æ„å»ºåå‘æ˜ å°„ï¼šquantæ¨¡å—å -> fpæ¨¡å—å
    reverse_mapping = {v: k for k, v in module_mapping.items()}

    # é€å±‚å¯¹æ¯”è¾“å‡º
    mismatch_found = False
    for quant_name, quant_out in quant_outputs.items():
        # è·³è¿‡æ²¡æœ‰å¯¹åº”çš„å±‚
        if quant_name.split('_', 1)[1] not in ['.'.join(k.split('.')[:-1]) for k in key_mapping.values()]:
            continue

        # æ‰¾åˆ°å¯¹åº”çš„fpæ¨¡å—è¾“å‡º
        fp_module = reverse_mapping.get(quant_modules[quant_name.split('_', 1)[1]], None)
        if not fp_module:
            continue

        fp_name = f"fp_{list(fp_modules.keys())[list(fp_modules.values()).index(fp_module)]}"
        fp_out = fp_outputs.get(fp_name)

        if fp_out is None:
            print(f"âš ï¸ æœªæ‰¾åˆ°å¯¹åº”è¾“å‡ºï¼š{fp_name} -> {quant_name}")
            continue

        # å¯¹æ¯”å¼ é‡
        try:
            if not torch.allclose(fp_out, quant_out, atol=1e-5):
                print("\n" + "=" * 80)
                print(f"âŒ è¾“å‡ºä¸åŒ¹é…ï¼š\nFP: {fp_name}\nQuant: {quant_name}")
                print(f"FP shape: {fp_out.shape} | Quant shape: {quant_out.shape}")
                print(f"æœ€å¤§ç»å¯¹è¯¯å·®: {torch.max(torch.abs(fp_out - quant_out)).item():.5e}")
                print(f"å¹³å‡ç»å¯¹è¯¯å·®: {torch.mean(torch.abs(fp_out - quant_out)).item():.5e}")
                print("=" * 80 + "\n")
                mismatch_found = True
                # break  # å‘ç°ç¬¬ä¸€ä¸ªå·®å¼‚å³åœæ­¢
            else:
                print(f"âœ… åŒ¹é…æˆåŠŸï¼š{fp_name.ljust(50)} -> {quant_name}")
        except RuntimeError as e:
            print(f"â›” å½¢çŠ¶ä¸åŒ¹é…ï¼š{fp_name} ({fp_out.shape}) vs {quant_name} ({quant_out.shape})")
            mismatch_found = True
            break

    if not mismatch_found:
        print("\nğŸ‰ æ‰€æœ‰å¯¹åº”å±‚è¾“å‡ºå®Œå…¨åŒ¹é…ï¼")

# DEVICE = 'cpu'
BATCH_SIZE = 64
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def main():

    # ä»JSONåŠ è½½é…ç½®æ–‡ä»¶
    model_json_file = "./config/model.json"
    config = load_config_from_json(model_json_file)
    quant_json_file = "./config/quantize.json"
    quant_params = load_config_from_json(quant_json_file)

    # conv_weight_qparams = {"weight_num_bits": 8, "weight_symmetric":True, "weight_signed": True}
    # conv_relu_qparams = {
    #     **conv_weight_qparams, 
    #     "act_num_bits": 8, "act_symmetric":False, "act_signed": False
    # }
    # conv_hswish_qparams = {
    #     **conv_weight_qparams, 
    #     "act_num_bits": 8, "act_symmetric":False, "act_signed": True
    # }
    # conv_hsigmoid_qparams = {
    #     **conv_weight_qparams, 
    #     "act_num_bits": 8, "act_symmetric":True, "act_signed": True
    # }
    


    # quant_params = {

    # }

    # åŠ è½½æµ®ç‚¹æ•°æ¨¡å‹å’Œæƒé‡
    fp_model = MobileNetV3(config = config, num_classes = 1000)
    load_weight_path = "./weights/fp32.pth"
    if load_weight_path is not None:
        print(f"Loading weights from {load_weight_path}")
        state_dict = torch.load(load_weight_path, map_location=DEVICE)
        # é€‚é…å¯èƒ½å­˜åœ¨çš„DataParallelå‰ç¼€
        state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
        fp_model.load_state_dict(state_dict, strict = False)

    # åŠ è½½é‡åŒ–æ¨¡å‹
    quant_model = QuantMobileNetV3(config = config, num_classes = 1000, quant_params = quant_params)


    # ç”Ÿæˆä»æµ®ç‚¹æ•°æ¨¡å‹åˆ°é‡åŒ–æ¨¡å‹çš„æƒé‡æ˜ å°„
    key_mapping = model_key_mapping(fp_model.state_dict(), quant_model.state_dict(), print_info = True)

    # è®©é‡åŒ–æ¨¡å‹åŠ è½½æµ®ç‚¹æ•°æ¨¡å‹çš„æƒé‡ ä½œä¸ºåˆå§‹æƒé‡
    quant_model.load_from_fp_model(fp_model, custom_mapping = key_mapping)

    fp_model.eval()
    quant_model.eval()

    # compare_models_layerwise(
    #     fp_model=fp_model,
    #     quant_model=quant_model,
    #     key_mapping=key_mapping,
    #     device=DEVICE,
    #     input_shape=(1, 3, 64, 64)  # æ ¹æ®ä½ çš„è¾“å…¥å°ºå¯¸è°ƒæ•´
    # )

    # åŠ è½½æ•°æ®é›†
    train_set, val_set, test_set = get_dataset("ImageNet1k_64")
    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)
    test_loader = val_loader
    

    # æµ‹è¯•æµ®ç‚¹æ•°ç²¾åº¦
    print("å¼€å§‹æµ‹è¯•åŸå§‹æ¨¡å‹ç²¾åº¦(fp_model)...")
    fp32_accuracy = evaluate_model(fp_model, test_loader, DEVICE)
    print(f"åŸå§‹æ¨¡å‹çš„æµ‹è¯•é›†å‡†ç¡®ç‡: {fp32_accuracy:.2f}%")


    quant_model.set_quant_state(quant_on = False, calib_on = False)
    print("å¼€å§‹æµ‹è¯•é‡åŒ–å‰çš„æ¨¡å‹ç²¾åº¦(quant_model, enable_quant = False)...")
    fp32_accuracy = evaluate_model(quant_model, test_loader, DEVICE)
    print(f"é‡åŒ–å‰æ¨¡å‹çš„æµ‹è¯•é›†å‡†ç¡®ç‡: {fp32_accuracy:.2f}%")

    # æµ‹è¯•æœªæ ¡å‡†ç²¾åº¦
    quant_model.set_quant_state(quant_on = True, calib_on = False)
    print("å¼€å§‹æµ‹è¯•é‡åŒ–åï¼ˆæœªæ ¡å‡†ï¼‰çš„æ¨¡å‹ç²¾åº¦...")
    quant_accuracy = evaluate_model(quant_model, test_loader, DEVICE)
    print(f"é‡åŒ–åï¼ˆæœªæ ¡å‡†ï¼‰æ¨¡å‹çš„æµ‹è¯•é›†å‡†ç¡®ç‡: {quant_accuracy:.2f}%")

    # æ ¡å‡†æ¨¡å‹,å¹¶æµ‹è¯•æ ¡å‡†åçš„ç²¾åº¦
    quant_model.set_quant_state(quant_on = False, calib_on = True)
    quant_model.calibrate(train_loader, DEVICE, num_batches=1000, verbose=True)
    quant_model.set_quant_state(quant_on = True, calib_on = False)

    print("å¼€å§‹æµ‹è¯•é‡åŒ–åï¼ˆå·²æ ¡å‡†ï¼‰çš„æ¨¡å‹ç²¾åº¦...")
    quant_accuracy = evaluate_model(quant_model, test_loader, DEVICE)
    print(f"é‡åŒ–åï¼ˆå·²æ ¡å‡†ï¼‰æ¨¡å‹çš„æµ‹è¯•é›†å‡†ç¡®ç‡: {quant_accuracy:.2f}%")




if __name__ == "__main__":
    main()
